---
layout: post
title: "[GoogleStudyJam] Introduction to Responsible AI"
date: 2024-03-31 23:38:00 +0900
categories: TIL
---

## 정리

### 왜 구글은 AI원칙을 수립했는가?

- 프로젝트 모든 단계에서 이루어진 결정에 AI원칙이 영향을 미친다. → 결정을 지지하지 않아도 프로세스를 신뢰할 수 있다.
- 자체 비즈니스 요구 사항과 가치에 맞게 AI를 설계할 수 있다.
- “책임 있는 AI”에 대한 보편적인 정의는 없기 때문에 조직이 자신의 사명과 가치를 반영하는 자체 AI원칙을 개발하고 있다.

### 구글의 AI 원칙 7가지

1. AI는 사회적으로 유익해야 한다.
2. AI는 불공정한 편견을 만들거나 강화하는 것을 피해야 한다.
3. AI는 안전성을 위해 구축되고 테스트되어야 한다.
4. AI를 사람들에게 설명할 수 있어야 한다.
5. AI는 개인 정보 보호 설계 원칙을 통합해야 한다.
6. AI는 높은 수준의 과학적 우수성을 유지해야 한다.
7. AI는 이러한 원칙에 부합하는 용도로 제공되어야 한다.

### 구글은 아래와 같은 AI를 설계하거나 배포하지 않을 것이다.

- 전반적으로 피해를 초래하거나 초래할 가능성이 있는 기술
- 사람에게 부상을 입히거나 이를 지원하는 것을 목적으로 하거나 구현하게 되는 무기
- 기타 기술정보를 수집하거나 감시용으로 사용함으로써 국제적으로 인정된 규범을 위반하는 기술
- 국제법과 인권에 관련하여 널리 수용되는 원칙에 위배되는 용도의 기술
